---
title: "Squeezing FLOPS out of a PlayStation Portable"
subtitle: "Exploring the Allegrex CPU, hand-tuning scalar code, writing VFPU assembly, porting to Rust, and benchmarking IO — all in pursuit of running a neural network on 2005 hardware."
date: 2026-02-01
tags: ["psp", "rust", "mips", "vfpu", "neural-networks", "embedded"]
---

The Sony PSP shipped in 2004 with a 333 MHz MIPS core, 32 MB of RAM, and a curious co-processor called the VFPU. It was designed to push polygons for handheld gaming. I wanted to see if it could run a modern neural network.

This post walks through every phase of that exploration: getting code to run on the hardware, understanding the compiler output at an instruction level, exploiting the VFPU for matrix math, porting to Rust, benchmarking IO, recording audio from the built-in mic, and validating the whole pipeline against a real bird classification model.

## Phase 1: Hello World — Understanding the Hardware

The first step was getting anything to run. The [pspdev](https://github.com/pspdev/pspdev) toolchain provides a full GCC cross-compiler targeting `mipsel-psp-elf`. On macOS, setup is straightforward:

```
curl -L https://github.com/pspdev/pspdev/releases/latest/download/pspdev-macos-latest-arm64.tar.gz | tar xz
xattr -rd com.apple.quarantine ./pspdev
export PSPDEV="$PWD/pspdev"
export PATH="$PSPDEV/bin:$PATH"
```

Hello world on the PSP looks like this:

```c
#include <pspkernel.h>
#include <pspdebug.h>
#include <pspdisplay.h>

PSP_MODULE_INFO("Hello", 0, 1, 0);
PSP_MAIN_THREAD_ATTR(THREAD_ATTR_USER);

#define printf pspDebugScreenPrintf

int main(void) {
    pspDebugScreenInit();
    printf("Hello from PSP!\n");
    while (1) { sceDisplayWaitVblankStart(); }
    return 0;
}
```

Simple enough. But what actually happens between `main()` and pixels on the LCD?

### The EBOOT.PBP Container

The PSP doesn't run ELFs directly. The SDK wraps the ELF in an `EBOOT.PBP` container — a format designed for the XMB (the PSP's menu system). The build pipeline strips debug sections and symbol tables from the ELF to produce a `DATA.PSP`, then bundles it with metadata like `PARAM.SFO`.

### Linking and Relocation

Looking at the relocatable object file, GCC puts our startup code in `.text.startup` rather than plain `.text`. This is a MIPS-specific optimization: since the Allegrex has a tiny 16 KiB instruction cache, isolating startup code in a separate section means it won't pollute the cache once we reach our hot path.

Before linking, function calls look like this:

```
8:  0c000000    jal  0 <main>     ; jump to address 0 (!)
```

A `jal 0` — jump and link to address zero. The compiler doesn't know the final address yet, so it writes a relocation entry:

```
Relocation section '.rel.text.startup':
 Offset     Info    Type          Sym. Name
00000008  00001004 R_MIPS_26     pspDebugScreenInit
```

This tells the linker: "8 bytes into `.text.startup`, patch the lower 26 bits with the address of `pspDebugScreenInit`." The upper 6 bits (the `JAL` opcode, `0x0C`) are preserved by the `R_MIPS_26` relocation type.

### Execution: No MMU, Just Load and Go

The PSP has no MMU. Loading a program is quite literal: `sceKernelCreateThread` allocates a thread control block (TCB), `sceKernelStartThread` sets it to `READY` and configures arguments. Context switching is the tricky part — we need the very registers we're trying to save in order to execute the save code.

### The Allegrex Instruction Cache

Understanding cache geometry matters a lot on this CPU because it's so small. The Allegrex has a 16 KiB, 2-way set-associative instruction cache with 64-byte lines:

```
16 KiB / 64 B per line = 256 lines total
256 lines / 2 ways   = 128 sets

Address decomposition (32 bits):
┌─────────────────────┬───────────┬──────────┐
│        Tag          │ Set Index │  Offset  │
│      (19 bits)      │ (7 bits)  │ (6 bits) │
└─────────────────────┴───────────┴──────────┘

Each set has 2 lines scanned in parallel for tag match.
Each line holds 16 instructions.
```

With only 256 cache lines total, every instruction counts. This constraint drives all the optimization work that follows.

### What Else Is Inside the Tachyon SoC

The PSP's Tachyon chip packs more than just the Allegrex CPU:

- **VFPU (COP2)** — 128 32-bit registers, can do a full 4×4 matrix multiply in 22 cycles. This is the star of the show.
- **Media Engine** — a second MIPS core dedicated to media encoding/decoding, not directly accessible to user code.
- **VME** — a reconfigurable DSP of sorts. Apparently no one has been able to fully interpret its firmware.
- **Graphics Engine** — communicates via MMIO registers at `0xBD400000`, driven by command packets (e.g., command `0x01` sets the vertex data start address).

## Phase 2: Optimizing Scalar Matrix Multiply

With a working dev environment, the real question is: how fast can we multiply matrices on this thing? Let's start with the obvious approach — a triple-nested loop in C.

```c
void mat_mul(const float *A, const float *B, float *C,
            int M, int N, int K) {
  for (int i = 0; i < M; i++)
    for (int j = 0; j < N; j++) {
      float sum = 0.0f;
      for (int k = 0; k < K; k++)
        sum += A[i*K + k] * B[k*N + j];
      C[i*N + j] = sum;
    }
}
```

Compiled with `-O2`, this produces 172 bytes of MIPS assembly. Let's look at what GCC gives us and whether we can do better.

### Reading the Assembly

The register allocation follows MIPS EABI conventions. Arguments arrive in `a0`–`a3` plus `t0` and `t1` for the 5th and 6th parameters. The hot inner loop is 7 instructions:

```asm
34: lwc1   $f0, 0(v0)        ; load A[i*K + k]
38: lwc1   $f2, 0(v1)        ; load B[k*N + j]
3c: addiu  v0, v0, 4         ; advance A pointer (contiguous)
40: addu   v1, v1, t1        ; advance B pointer (strided)
44: mul.s  $f0, $f0, $f2     ; single-precision multiply
48: bne    a0, v0, 0x34      ; loop if more k values
4c: add.s  $f1, $f1, $f0     ; (delay slot) sum += product
```

That last instruction is in the *branch delay slot* — on MIPS, the instruction after a branch always executes, regardless of whether the branch is taken. GCC cleverly places the accumulation there, overlapping it with loop control for free.

### Eliminating Dead Code with \_\_builtin\_unreachable

Even at `-O2`, GCC generates some waste. There are early-exit checks for M ≤ 0 and N ≤ 0, plus a fallback loop that zero-fills C when K ≤ 0. We know our dimensions are always positive, so these paths are dead weight.

The zero-fill fallback is particularly wasteful. If the inner loop never runs because K ≤ 0, `sum` is still zero and needs to be stored. GCC synthesizes a 5-instruction loop guarded by a `bgtz` just to write zeros:

```asm
38: addiu  t4, t4, 1       ; j++
3c: sw     zero, 0(t3)     ; C[i*N + j] = 0
40: addiu  t5, t5, 4       ; advance B pointer (unused!)
44: bne    t0, t4, 0x38    ; loop until done
48: addiu  t3, t3, 4       ; (delay slot) advance C pointer
```

We can tell GCC that these paths are impossible:

```c
if (M <= 0) __builtin_unreachable();
if (N <= 0) __builtin_unreachable();
if (K <= 0) __builtin_unreachable();
```

### The Cascade Effect

I expected removing 3 early-exit instructions and a 6-instruction zero-fill loop. But the savings cascaded further. The original code had two duplicate return blocks (the M and N exits jumped to different copies of `jr ra`), and a trampoline branch to handle the store after the last iteration of the inner loop. With the dead paths removed, the store falls through naturally.

> **Result:** 3 + 6 + 2 + 1 = 12 instructions removed. 172 bytes → 124 bytes. The entire `mat_mul` now fits in **2 cache lines** instead of 3 — reducing cache pressure by 0.39% on a CPU that only has 256 lines to begin with.

The original code layout had this structure:

```
0x00  [entry + guards]
0x10  [outer loop setup]
0x24  [middle loop start]
0x30    bgtz t1, 0x78  ───────┐  "if K > 0, goto inner loop"
0x38    [zero-fill fallback]  │
0x4c  [outer loop advance]    │
0x60  [return]                │
0x68  [store + advance j]     │  ← trampoline target
0x78  [inner loop setup]  ◄───┘
0x84  [inner loop body]
0x98    bne → 0x84            "loop back if more k"
0xa0    b → 0x68              ← extra branch to store
0xa8  [duplicate return]
```

After the optimization, it collapses to a clean linear flow:

```
0x00  [setup]
0x18  [outer loop]
0x28    [inner loop setup]
0x34    [inner loop body]
0x48    bne → 0x34        "loop back if more k"
0x50  [store + advance j] ← falls through, no trampoline
0x5c    bne → 0x28        "next j"
0x64  [outer loop advance]
0x70    bne → 0x18        "next i"
0x78  [return]
```

### Why Not Unroll?

Normally you'd consider unrolling a 7-instruction loop. But MIPS branching is cheap — the only penalty is the delay slot, and GCC already fills it productively. Unrolling would increase code size (more cache pressure) and register pressure, with no fused multiply-add to exploit (MIPS32 lacks `madd.s`, which only appears in MIPS IV). Not worth it on this hardware.

## Phase 3: Unleashing the VFPU

The VFPU is the PSP's secret weapon for number crunching. It has 128 32-bit floating-point registers organized as 8 primitive 4×4 matrices, and — crucially — a single instruction that performs a full 4×4 matrix multiply: `vmmul.q`.

### Register Architecture

VFPU registers use a prefix-based naming scheme. The prefix indicates dimensionality: `S` for single, `R` for row vector, `C` for column vector, `M` for matrix. Instructions have a suffix indicating width: `.s` (scalar), `.p` (pair), `.t` (triple), `.q` (quad).

A critical detail: sub-vectors and sub-matrices *never cross primitive matrix boundaries*. Addressing modes can alias the same physical register — for example, row vector `R000` and column vector `C000` share element `S000`. Some VFPU instructions require that input and output registers don't overlap in this way. The [pspdev VFPU docs](https://pspdev.github.io/vfpu-docs/docs.pdf) are an excellent reference.

### The Column-Major Surprise

The SDK ships with `openTri`, which includes a `triMat4Mul` routine. Disassembling it revealed something puzzling:

```asm
move   v0, a0            ; save output pointer
lv.q   C100, 0(a1)       ; load rows of B as column vectors
lv.q   C110, 16(a1)
lv.q   C120, 32(a1)
lv.q   C130, 48(a1)
lv.q   C200, 0(a2)       ; load rows of C as column vectors
lv.q   C210, 16(a2)
lv.q   C220, 32(a2)
lv.q   C230, 48(a2)
vmmul.q E000, E200, E100  ; matrix multiply
sv.q   C000, 0(a0)       ; store result as column vectors
sv.q   C010, 16(a0)
sv.q   C020, 32(a0)
sv.q   C030, 48(a0)
jr     ra
```

It loads row-major C data into column vectors, reverses the multiplication order, then stores column data back as rows. Why all the gymnastics?

I initially thought this was wrong. I had Claude write a test harness that compiled an EBOOT.PBP and ran it in PPSSPP. The VFPU result came out transposed compared to the scalar version:

```
Scalar:       VFPU (tri):
19  22        23  34
43  50        31  46
```

Then it clicked: the **VFPU is natively column-major**. S₀₁ is one *row* below S₀₀, not one column to the right. But C arrays are row-major. The `openTri` code loads row-major data into column registers, effectively transposing on load, multiplies in transposed space, then transposes back on store. It's actually correct — just expensive if you include the transposes.

### A Direct Approach

Instead of fighting the column-major convention, we can load data into row registers directly:

```c
void mat_mul_4x4_vfpu(float *C, const float *A, float *B) {
  __asm__ volatile(
    "lv.q   R000,  0(%1)\n"    // row 0 of A → row 0 of M0
    "lv.q   R001, 16(%1)\n"    // row 1 of A → row 1 of M0
    "lv.q   R002, 32(%1)\n"    // row 2 of A → row 2 of M0
    "lv.q   R003, 48(%1)\n"    // row 3 of A → row 3 of M0
    "lv.q   R100,  0(%2)\n"    // row 0 of B → row 0 of M1
    "lv.q   R101, 16(%2)\n"    // row 1 of B → row 1 of M1
    "lv.q   R102, 32(%2)\n"    // row 2 of B → row 2 of M1
    "lv.q   R103, 48(%2)\n"    // row 3 of B → row 3 of M1
    "vmmul.q M200, M000, M100\n" // M2 = M0 × M1
    "sv.q   R200,  0(%0)\n"    // store result rows
    "sv.q   R201, 16(%0)\n"
    "sv.q   R202, 32(%0)\n"
    "sv.q   R203, 48(%0)\n"
    : : "r"(C), "r"(A), "r"(B) : "memory"
  );
}
```

### Profiling

The PSP has hardware performance counters at `0xBC400000`, but PPSSPP doesn't implement the backing memory — attempting to use `pspDebugProfilerEnable` crashes the emulator with a segfault as the MMU page-faults on the unmapped address. Instead, I used `sceKernelGetSystemTimeLow` with 10,000 iterations:

| Implementation | Emulator (PPSSPP) | Real PSP |
|---|---|---|
| Scalar 4×4 | 28,440 μs | 48,024 μs |
| VFPU (openTri, pre-transposed) | 16,877 μs | — |
| VFPU (inline asm) | 1,307 μs | 2,853 μs |

Our inline assembly is nearly **12× faster** than the `openTri` implementation when transposes are included. Once you factor out the transpose overhead, both VFPU paths converge to roughly the same speed — about 1,300 μs for 10,000 calls in the emulator.

### Sanity-Checking the Numbers

The `vmmul.q` instruction has a throughput of 16 cycles and a latency of 22 cycles. Our full operation is 8 loads + 1 vmmul (22 cycles) + 4 stores + ~3 cycles loop overhead ≈ 37 cycles minimum per multiply. The Allegrex runs at 333 MHz:

```
1,300 μs × 333 cycles/μs = 432k cycles
432k / 10k iterations   = 43.2 cycles/iteration
```

That's about 14% overhead beyond the theoretical minimum — reasonable for emulation.

> **Real hardware is different.** On the actual PSP, the VFPU speedup over scalar is 16.8× compared to 21.7× in the emulator. The emulator likely implements VFPU operations more efficiently on modern hardware, without the real register overlap constraints.

### Enabling the VFPU for PRX Modules

One gotcha when running via PSPLINK: the VFPU must be explicitly enabled via a thread attribute. Without `THREAD_ATTR_VFPU`, attempting any VFPU instruction triggers a "Coprocessor unusable" exception:

```
Exception - Coprocessor unusable
Thread ID - 0x042DB813
EPC       - 0x08806B48
Cause     - 0x2000002C
```

The `EPC` (Exception Program Counter) points to the faulting instruction. Cross-referencing with the disassembly at the corresponding PRX offset confirms it's the first `lv.q` instruction. The fix is a single flag:

```c
PSP_MAIN_THREAD_ATTR(THREAD_ATTR_USER | THREAD_ATTR_VFPU);
```

## Phase 4: Porting to Rust and Measuring IO

With the C implementation validated, I wanted to see if Rust could target the PSP too. The [cargo-psp](https://github.com/overdrivenpotato/rust-psp) project makes this possible, compiling for the `mipsel-sony-psp` target.

### How cargo-psp Works

The build pipeline mirrors what the C toolchain does, but through Rust's build infrastructure:

```
cargo build \
  -Z build-std=core,compiler_builtins,alloc,panic_unwind,panic_abort \
  --target mipsel-sony-psp \
  --message-format=json-render-diagnostics
```

After compilation, `cargo-psp` runs the same post-processing: `prxgen` to convert ELF → PRX, `MKSFO` for metadata, and `pbp-pack` to produce the final `EBOOT.PBP`.

### The PSP's Dynamic Linking Model

One fascinating detail that becomes very visible when working with `cargo-psp` is how the PSP resolves system calls. Unlike a typical OS where libc wraps syscalls, the PSP patches them at load time. When your code calls `sceDisplayWaitVblankStart`, the compiler emits a jump to a stub, and the actual syscall number gets patched in by the firmware loader.

The PRX contains four special sections that the kernel uses for this:

```
// 1. Library names
.rodata.sceResident   → "sceDisplay", "sceNet", ...

// 2. Function IDs (32-bit hashes)
.rodata.sceNid        → sceDisplayWaitVblankStart = 0x984C27E7

// 3. Stub code (placeholder, patched by firmware)
.sceStub.text         → jr $ra; syscall N

// 4. Index tying it all together
.lib.stub             → { name, nid_table, stub_table, count }
```

The kernel walks `.lib.stub`, resolves each library name, looks up the NIDs, and patches the corresponding stubs with the correct syscall numbers. Your code only includes stubs for functions it actually calls, and the kernel only loads what's needed.

```
.text                          .sceStub.text
─────                          ──────────────
jal 0xf1f8  ──────────────────►  [placeholder data]
                                       │
                                       │ PSP loader patches
                                       ▼
                                  jr $ra
                                  syscall N
```

### VFPU in Rust

The Rust version uses the `vfpu_asm!` macro (nightly-only, requires `#![feature(asm_experimental_arch)]`) and looks nearly identical to the C inline assembly:

```rust
unsafe {
    vfpu_asm!(
        "lv.q R000,  0({0})",
        "lv.q R001, 16({0})",
        "lv.q R002, 32({0})",
        "lv.q R003, 48({0})",
        "lv.q R100,  0({1})",
        "lv.q R101, 16({1})",
        "lv.q R102, 32({1})",
        "lv.q R103, 48({1})",
        "vmmul.q M200, M000, M100",
        "sv.q R200,  0({2})",
        "sv.q R201, 16({2})",
        "sv.q R202, 32({2})",
        "sv.q R203, 48({2})",
        in(reg) (a.as_ptr()),
        in(reg) (b.as_ptr()),
        in(reg) (c.as_mut_ptr()),
        options(nostack),
    );
}
```

### IO Benchmarks: How Fast Can We Feed the Beast?

For neural network inference, we need to load model weights into RAM. The PSP's primary data path during development is USB via PSPLINK, which exposes a virtual filesystem (`host0:`) backed by the `usbhostfs` driver.

The PSP's IO stack goes through `IoFileMgrForUser`, which parses the device prefix (`ms0:` for Memory Stick, `host0:` for USB, etc.) and forwards to the appropriate driver. The USB driver uses bulk transfers with a maximum block size of 64 KiB for reads:

```c
#define HOSTFS_MAX_BLOCK   (64*1024)     // max read block
#define HOSTFS_BULK_MAXWRITE (1024*1024)  // max write block
```

Before each DMA transfer, the driver calls `sceKernelDcacheWritebackRange` to flush dirty cache lines — otherwise the DMA hardware might read stale data from main memory.

Benchmarking 4 MiB transfers in 64 KiB blocks on real hardware:

| Direction | Bandwidth | Time (4 MiB) |
|---|---|---|
| Read (USB → PSP) | 22.81 MiB/s | 175 ms |
| Write (PSP → USB) | 14.90 MiB/s | 268 ms |

### Can We Actually Run a Neural Network?

Let's do the math for [BirdNET v2.4](https://birdnet-team.github.io/BirdNET-Analyzer/models.html), a bird species classification model:

| Parameter | Value |
|---|---|
| Model size (FP32) | 50.5 MB |
| Load time over USB | ~2.21 s |
| Total FLOPs | 826 MFLOP |
| Measured VFPU throughput | 348 MFLOP/s |
| Inference time (estimate) | ~2.37 s |
| RAM remaining after model | ~16 MB |

That throughput estimate comes from our benchmark: 10,000 4×4 matmuls, each consisting of 64 multiplies + 48 adds = 112 FLOPs, totaling 1.12 MFLOP completed in 3,218 μs — about 348 MFLOP/s.

> **Verdict:** ~5 seconds from cold start to first inference. That's tight but workable. And there's headroom — 348 MFLOP/s is well below the VFPU's theoretical peak of 3.2 GFLOP/s. With better data tiling, double-buffered loads, and careful use of the VFPU's 8 matrix registers, we should be able to push significantly harder.

## Phase 5: Recording Audio on the PSP

If we're going to classify birdsong, we need microphone access. The PSP has a built-in mic, but the homebrew landscape for audio recording is sparse. The only existing tool I found was [PSP Audio Recorder](https://www.gamebrew.org/wiki/PSP_Audio_Recorder) from 2006, which runs as a kernel module — making it impossible to load over PSPLINK during development. I decided to write a new recorder from scratch in Rust.

### The Kernel Module Problem

The original C audio recorder uses a two-stage loader pattern typical of PSP kernel modules. A user-mode stub loads the actual kernel PRX:

```c
PSP_MODULE_INFO("BOOT_PRX", 0x1000, 1, 1);  // 0x1000 = kernel mode

int main_thread(SceSize args, void *argp) {
    pspKernelSetKernelPC();
    pspSdkInstallNoDeviceCheckPatch();
    pspSdkInstallNoPlainModuleCheckPatch();
    // ... load and start record.prx
    mod = sceKernelLoadModule(path, 0, NULL);
    mod = sceKernelStartModule(mod, ...);
}
```

This requires kernel-level privileges, custom firmware patches, and a separate PRX build — far too cumbersome for iterative development. The good news: `sceAudioInputBlocking` actually works in user mode on modern custom firmware, so we can skip all of that.

### A User-Mode Recorder in Rust

The Rust implementation is straightforward. We use `sceAudioInputInit` to set up the mic, then call `sceAudioInputBlocking` in a loop to fill 1024-sample buffers at 44.1 kHz, 16-bit mono:

```rust
fn record_chunk(&mut self) {
    let mut buf = [0i16; 1024];
    unsafe {
        sceAudioInputBlocking(
            buf.len() as i32,
            self.get_input_freq(),
            buf.as_mut_ptr() as *mut c_void,
        );
    }
    self.samples.extend_from_slice(&buf);
}
```

Samples are collected into a `Vec<i16>` (we get an allocator via `extern crate alloc`), then written out as a WAV file with a manually constructed 44-byte header. The WAV format is simple enough to build by hand — just RIFF/WAVE container metadata followed by raw PCM data.

### Offline-First Design

An interesting design constraint: the PSP might not always be tethered to a PC via USB. The recorder handles this with a two-tier storage strategy. When `host0:` is available (connected via PSPLINK), recordings save directly to the host PC. When it's not, they cache to the Memory Stick at `ms0:/PSP/MUSIC/AUDREC/`. On next connection, the app detects cached recordings and offers to upload them.

We detect connectivity by attempting to open `host0:/` as a directory — if `sceIoDopen` returns a non-negative file descriptor, we're connected:

```rust
fn is_host0_available() -> bool {
    let fd = unsafe { sceIoDopen(b"host0:/\0".as_ptr()) };
    if fd.0 >= 0 {
        unsafe { sceIoDclose(fd) };
        true
    } else { false }
}
```

## Phase 6: Can the PSP's Mic Hear Birds?

Before building an entire on-device inference engine, there's a fundamental question: is the PSP's microphone even good enough to capture birdsong at a quality that BirdNET can recognize? The mic was designed for voice chat in games, not field recording.

I recorded a few clips from my living room — birds singing outside, not particularly close — and uploaded them to [birdnet.cornell.edu/demo](https://birdnet.cornell.edu/demo/).

It worked. BirdNET identified a Dark-eyed Junco (*Junco hyemalis*) from a PSP recording. The spectrogram showed clean frequency content in the relevant bands despite the consumer-grade hardware.

> **Validation:** The PSP's built-in microphone produces audio of sufficient quality for neural network-based bird species classification. This confirms the end-to-end pipeline is feasible — the remaining work is purely computational.

## Phase 7: Error Handling in `no_std` Rust

As the codebase grew, debugging became painful. PSP syscalls return errors as negative `i32` values — for example, opening a non-existent file returns `-2147418110`. Not exactly self-documenting.

### PSP Error Code Anatomy

PSP error codes follow the format `0x8XYYNNNN`, where different prefixes indicate the subsystem:

| Prefix | Category |
|---|---|
| `0x8000XXXX` | Common/generic errors |
| `0x8001XXXX` | POSIX errno (maps directly to C errno values) |
| `0x8002XXXX` | Kernel errors |
| `0x8021XXXX` | UMD errors |

The `0x8001XXXX` range is particularly useful — the lower 16 bits map directly to POSIX errno values: `0x80010002` is `ENOENT` (errno 2, "No such file or directory"), `0x8001000D` is `EACCES` (errno 13, "Permission denied"), and so on.

### Why Not Just Use `strerror()`?

My first instinct was to call newlib's `strerror()` via FFI:

```rust
#[link(name = "c")]
extern "C" {
    fn strerror(errnum: c_int) -> *const c_char;
}
```

This doesn't work. `rust-psp` is a pure `no_std` environment that doesn't link against newlib. When I tried to force-link PSP's `libc.a`, the linker couldn't find it without an explicit search path, and once found, it produced ABI errors (`symbol has invalid binding: 0`). The PSP SDK's libc was compiled with `psp-gcc` using a slightly different MIPS ABI than what `rust-lld` expects. Fixing this would mean invasive changes to `rust-psp`'s build system — not worth it for error strings.

### A Manual Lookup Table

The practical solution is a simple match table:

```rust
fn psp_strerror(code: i32) -> &'static str {
    let code = code as u32;
    match code {
        0x80010002 => "ENOENT: No such file or directory",
        0x8001000D => "EACCES: Permission denied",
        0x80000022 => "SCE_ERROR_OUT_OF_MEMORY",
        // ... ~30 more entries
        _ => match code & 0xFFFF0000 {
            0x80010000 => "Unknown POSIX errno",
            0x80020000 => "Unknown kernel error",
            _ => "Unknown error",
        }
    }
}
```

The fallback arm uses a masked match on the upper 16 bits to at least categorize unknown errors by subsystem. This works in `no_std` with zero external dependencies, and could be contributed upstream to `rust-psp` as a `psp::error` module.

```
// Before:
dprintln!("Error: {}", fd.0);
//   Error: -2147418110

// After:
dprintln!("Error: {:#010x} {}", fd.0 as u32, psp_strerror(fd.0));
//   Error: 0x80010002 ENOENT: No such file or directory
```

## What I Learned

Working on a system with no MMU, 256 instruction cache lines, and a 333 MHz clock forces you to think about every instruction. The PSP is a surprisingly well-designed piece of silicon — the VFPU alone provides a 17× speedup over scalar code on real hardware, and the architecture rewards careful attention to cache geometry and register layout.

The journey from "Hello from PSP!" to recording birdsong and validating neural network feasibility touched on compiler internals (relocation tables, CRT startup code), CPU microarchitecture (cache line budgets, branch delay slots), coprocessor programming (VFPU register aliasing, column-major conventions), systems programming (PRX loading, syscall patching, DMA cache coherency), audio capture (rewriting a kernel module as a user-mode Rust app), and the realities of `no_std` Rust on exotic hardware (no libc linking, manual error tables, ABI mismatches between `psp-gcc` and `rust-lld`).

The most satisfying moment: uploading a WAV file recorded on 2005 hardware to a 2024 neural network demo and watching it identify a Dark-eyed Junco. The PSP's mic works, the VFPU has headroom, and the IO budget is tight but feasible. Next step: build the actual on-device inference engine.

---

*Built with a cross-compiler, a lot of `objdump`, and a PSP that still has battery life after 20 years.*
